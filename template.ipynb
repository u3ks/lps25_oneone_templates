{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d726fbf",
   "metadata": {},
   "source": [
    "# EarthCode 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37177a",
   "metadata": {},
   "source": [
    "\n",
    "## About EarthCODE\n",
    "\n",
    "EarthCODE ([earthcode.esa.int](https://earthcode.esa.int)) is ESA‚Äôs strategic initiative to bring this vision to life. Originally starting as a simple repository for datasets from ESA-funded projects, it has since grown into a comprehensive environment that supports the full open science lifecycle‚Äîfrom data and workflow development to publication and community engagement.\n",
    "\n",
    "![](images/whatis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b10f89",
   "metadata": {},
   "source": [
    "## Open Science Catalog\n",
    "\n",
    "\n",
    "You can explore the Open Science Catalog from any web browser by navigating to:\n",
    "\n",
    "üëâ [https://opensciencedata.esa.int/](https://opensciencedata.esa.int/)\n",
    "\n",
    "Upon entering the portal, you will see a welcome page that introduces the catalog and its functionalities. The catalog organizes resources into six thematic research domains, allowing users to easily browse and discover relevant projects, products, workflows, and experiments.\n",
    "\n",
    "From the landing page, you can also access:\n",
    "\n",
    "- Search tools for locating products\n",
    "- Catalog to browse available products\n",
    "- Metrics to explore data availability statistics\n",
    "- API capabilities for programmatic access\n",
    "\n",
    "![OSC-main-page](https://github.com/EOEPCA/open-science-catalog-metadata/assets/120453810/a97e40c1-0f69-4204-9aef-95030c5a8455)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36082fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Working with Platforms\n",
    "\n",
    "EarthCODE partners with a growing ecosystem of platforms to provide FAIR and Open Earth Observation science tools and infrastructure!\n",
    "\n",
    "![](images/platforms.png)\n",
    "\n",
    "The EarthCODE integrated platforms can either be self-sponsored if your team already have access to them. You can alternatively apply for sponsorship from the [Network of Resources](https://nor-discover.org/) for access & resources on your selected platform. Please refer to the [NoR Tutorial Page](../../Training%20and%20Resources/NoR.md) for more details about making a NoR application.\n",
    "\n",
    "![](images/norr.png)\n",
    "\n",
    "\n",
    "__NOTE__: You can work locally and/or on custom hardware and upload metadata to the OSC or PRR seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77406b67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Community effort\n",
    "\n",
    "EarthCODE‚Äôs [Discourse](https://discourse-earthcode.eox.at/) is a community for EarthCODE users to engage in discussions about FAIR and open-science, share insights, and explore the diverse tools and solutions offered by the platform\n",
    "\n",
    "This forum serves as a shared space where scientists, researchers, and practitioners come together to advance Earth science through open discussion and knowledge sharing. \n",
    "\n",
    "\n",
    "![](images/community.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6461",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Publishing Data\n",
    "\n",
    "A detailed description and examples of how to publish data to the OSC is available [here](https://esa-earthcode.github.io/documentation/Technical%20Documentation/Data/Contributing%20to%20the%20EarthCODE%20Catalog#how-to-publish-results). But in summary, you'll have to :\n",
    "\n",
    "1. **Prepare your Product Package (Research Experiment)**, by uploading **dataset files**, **code** and **documentation** to appropriate, accessible locations.\n",
    "\n",
    "2. **Generate a Self-Contained STAC Collection**\n",
    "   - Use tools like [`stactools`](https://stactools.readthedocs.io/en/stable/), [`rio-stac`](https://github.com/developmentseed/rio-stac), or [`PySTAC`](https://pystac.readthedocs.io/en/stable/) to generate a STAC collection.\n",
    "   - Generate the relevant Stac Items.\n",
    "   - Host the resulting JSON files (Catalog + Items) in a **public GitHub repository** (or institutional equivalent).\n",
    "\n",
    "\n",
    "   >     Make sure the Collection uses **relative paths** and points to remote asset URLs!\n",
    "\n",
    "\n",
    "3. **Describe Your Research in the Open Science Catalog**\n",
    "   - Create entries that describe your **dataset, workflow, and experiment**.\n",
    "   - Link them to relevant **projects, variables, themes, and EO missions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75154a",
   "metadata": {},
   "source": [
    "## PRR\n",
    "\n",
    "The ESA Project ResultsRrepository hosts value added products from several ESA EOP-S Projects and provides persistant storage. It is one option where to keep your datasets and the metadata that describes them.\n",
    "\n",
    "\n",
    "### General information required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac import Collection\n",
    "\n",
    "collection = Collection.from_dict(\n",
    "    \n",
    "{\n",
    "  \"type\": \"Collection\",\n",
    "  \"id\": \"\",\n",
    "  \"stac_version\": \"1.1.0\",\n",
    "  \"title\": \"\",\n",
    "  \"description\": \"\",\n",
    "  \"extent\": {\n",
    "    \"spatial\": {\n",
    "      \"bbox\": [\n",
    "        [\n",
    "          -180.0,\n",
    "          -90.0,\n",
    "          180.0,\n",
    "          90.0\n",
    "        ]\n",
    "      ]\n",
    "    },\n",
    "    \"temporal\": {\n",
    "      \"interval\": [\n",
    "        [\n",
    "          \"1982-01-01T00:00:00Z\",\n",
    "          \"2022-12-31T23:59:59Z\"\n",
    "        ]\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "\"license\": \"CC-BY-4.0\",\n",
    "\"links\": []\n",
    "\n",
    "}\n",
    "\n",
    ")\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea714230",
   "metadata": {},
   "source": [
    "### Data Structure\n",
    "\n",
    "1. How do we read your data?\n",
    "2. What is the structure of it?\n",
    "\n",
    "\n",
    "The STAC structure helps organize and describe your data in a consistent and machine-readable way. Its important to specify the best expected structure for the data, to increase usability. This varies based on project and data type.\n",
    "\n",
    "Once the data structure is specified, you can describe it using Stac Items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72b7d0",
   "metadata": {},
   "source": [
    "One way to create an Item Catalog is to copy an existing catalog and edit it manually in a text editor to fit your data. If you're new to STAC and only have a few data assets, this approach can work, but it is prone to errors.\n",
    "\n",
    "Manually editing STAC Items can be tedious, and extracting all the required metadata correctly can be challenging. For most Item Catalogs, we recommend using automated tools, for example:\n",
    "\n",
    "The stactools CLI provides a simple command-line interface for generating STAC Items. With the stactools-datacube extension even following the STAC datacube extension.\n",
    "A combination of PySTAC to create the Catalog and rio-stac for automatically generating valid STAC Items with all required metadata.\n",
    "Typically, this workflow starts by defining individual STAC objects (a Catalog and its Items). Once created, these objects are linked together using STAC relationships.\n",
    "\n",
    "## Using rio_stac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e8b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cfd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rio_stac\n",
    "import pystac\n",
    "from rio_stac import create_stac_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20171111T205337_20171111T205438_008239_00E91A_F8D1.tif\",\n",
    "    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20190224T203744_20190224T203844_015093_01C356_B9C1.tif\",\n",
    "    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20170620T205332_20170620T205433_006139_00AC89_6857.tif\",\n",
    "    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20180923T202118_20180923T202218_012847_017B82_7DD5.tif\",\n",
    "    \"https://zenodo.org/records/7568049/files/extent_S1B_EW_GRDH_1SDH_20181108T203747_20181108T203847_013518_01903B_D463.tif\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b088e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = create_stac_item(\n",
    "    source=filenames[0],\n",
    "    id=\"item_1\",\n",
    "    asset_name=\"data\",  # EarthCODE standard asset name\n",
    "    # all the metadata!\n",
    "    with_eo=True,\n",
    "    with_proj=True,\n",
    "    with_raster=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7562e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add_item(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.normalize_and_save(root_href='../../data/example_collection/', catalog_type=pystac.CatalogType.SELF_CONTAINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c35efc",
   "metadata": {},
   "source": [
    "# Using pySTAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### download all the stac items associated with the project\n",
    "\n",
    "root_url = 'https://eoresults.esa.int'\n",
    "all_item_paths = []\n",
    "next_link = 'https://eoresults.esa.int/stac/collections/sentinel3-ampli-ice-sheet-elevation/items'\n",
    "\n",
    "while next_link is not None:\n",
    "    \n",
    "    print(next_link)\n",
    "    next_items_to_process = pystac.ItemCollection.from_file(next_link)\n",
    "\n",
    "    for item in next_items_to_process.items:\n",
    "\n",
    "        for (k, asset) in item.get_assets().items():\n",
    "            all_item_paths.append(root_url + asset.href)\n",
    "    \n",
    "    next_link = None\n",
    "\n",
    "    # if 'links' in next_items_to_process.extra_fields:\n",
    "    #     for link in next_items_to_process.extra_fields['links']:\n",
    "    #             if link['rel'] == 'next':\n",
    "    #                 next_link = link['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by mission, region and cycle extracted from the filename\n",
    "\n",
    "data = []\n",
    "\n",
    "for path in all_item_paths:\n",
    "    \n",
    "    if path[-3:] != '.nc':\n",
    "        continue\n",
    "\n",
    "    filename = path.split('/')[-1]\n",
    "    split = filename.split('_')\n",
    "    data.append((split[0], split[9], split[-2], path))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['mission', 'cycle', 'region', 'path'])\n",
    "for ((mission, region, cycle), paths) in df.groupby(['mission', 'region', 'cycle'])['path']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6038f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if its a remote netcdf file\n",
    "# datasets = [xr.open_dataset(p+'#mode=bytes', engine=\"netcdf4\") for p in paths.values[:10]]\n",
    "\n",
    "# if its local\n",
    "datasets = [xr.open_dataset(p, engine=\"netcdf4\") for p in paths.values[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign metadata for each item\n",
    "\n",
    "\n",
    "# Load geometries\n",
    "geoms = [json.loads(ds.attrs['geo_footprint']) for ds in datasets]\n",
    "geometry_union = unary_union(geoms)\n",
    "geometry = json.loads(json.dumps(geometry_union.__geo_interface__))\n",
    "bbox = list(geometry_union.bounds)\n",
    "\n",
    "# Temporal extent\n",
    "first_item = datasets.iloc[0]\n",
    "last_item = datasets.iloc[-1]\n",
    "\n",
    "props = first_item.attrs\n",
    "props2 = last_item.attrs\n",
    "start_datetime = props.get(\"start_datetime\")\n",
    "end_datetime = props2.get(\"end_datetime\")\n",
    "\n",
    "# Shared properties\n",
    "properties = {\n",
    "    \"start_datetime\": start_datetime,\n",
    "    \"end_datetime\": end_datetime,\n",
    "    \"created\": props.get(\"created\"),\n",
    "    \"description\": \"Sentinel-3 AMPLI Land Ice Level-2 product acquired by Sentinel-3A platform derived from the SRAL altimeter in Earth Observation mode over Antarctica region.\",\n",
    "    \"conventions\": props.get(\"conventions\"),\n",
    "    \"platform_name\": props.get(\"platform_name\"),\n",
    "    \"platform_serial_identifier\": props.get(\"platform_serial_identifier\"),\n",
    "    \"altimeter_sensor_name\": props.get(\"altimeter_sensor_name\"),\n",
    "    \"operational_mode\": props.get(\"operational_mode\"),\n",
    "    \"cycle_number\": props.get(\"cycle_number\"),\n",
    "    \"netcdf_version\": props.get(\"netcdf_version\"),\n",
    "    \"product_type\": props.get(\"product_type\"),\n",
    "    \"timeliness\": props.get(\"timeliness\"),\n",
    "    \"institution\": props.get(\"institution\"),\n",
    "    \"processing_level\": props.get(\"processing_level\"),\n",
    "    \"processor_name\": props.get(\"processor_name\"),\n",
    "    \"processor_version\": props.get(\"processor_version\"),\n",
    "    \"references\": props.get(\"references\"),\n",
    "    \"zone\": props.get(\"zone\"),\n",
    "}\n",
    "\n",
    "# Create STAC item for the cycle\n",
    "item = pystac.Item(\n",
    "    id=f\"sentinel-3a-antarctica-{cycle.lower()}\",\n",
    "    geometry=geometry,\n",
    "    bbox=bbox,\n",
    "    datetime=isoparse(start_datetime),\n",
    "    properties=properties\n",
    ")\n",
    "\n",
    "item.stac_version = \"1.1.0\"\n",
    "item.stac_extensions = [\n",
    "    \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\",\n",
    "    \"https://stac-extensions.github.io/raster/v1.1.0/schema.json\",\n",
    "    \"https://stac-extensions.github.io/eo/v1.1.0/schema.json\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "item.assets = {}\n",
    "\n",
    "# Add assets from that cycle\n",
    "for path in item_paths:\n",
    "    with fs.open(path, \"r\") as f:\n",
    "        item_data = json.load(f)\n",
    "        asset_title = item_data[\"properties\"].get(\"title\")\n",
    "        nc_asset = item_data.get(\"assets\", {}).get(\"data\")\n",
    "        if not nc_asset:\n",
    "            print(f\"‚ö†Ô∏è No 'data' asset in {path}, skipping.\")\n",
    "            continue\n",
    "        nc_href = nc_asset[\"href\"]\n",
    "        if nc_href.startswith(prefix_to_strip):\n",
    "            nc_href = nc_href.replace(prefix_to_strip, \"\")\n",
    "\n",
    "        asset_props = item_data.get(\"properties\", {})\n",
    "        extra_fields = {\n",
    "            \"cycle_number\": asset_props.get(\"cycle_number\"),\n",
    "            \"orbit_number\": asset_props.get(\"orbit_number\"),\n",
    "            \"relative_orbit_number\": asset_props.get(\"relative_orbit_number\"),\n",
    "            \"orbit_direction\": asset_props.get(\"orbit_direction\"),\n",
    "        }\n",
    "\n",
    "        item.add_asset(\n",
    "            key=asset_title,\n",
    "            asset=pystac.Asset(\n",
    "                href=nc_href,\n",
    "                media_type=\"application/x-netcdf\",\n",
    "                roles=[\"data\"],\n",
    "                extra_fields=extra_fields\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save STAC item per cycle\n",
    "json_filename = f\"sentinel-3a-antarctica-{cycle.lower()}.json\"\n",
    "item.save_object(dest_href=json_filename, include_self_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e4de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ae68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f488757",
   "metadata": {},
   "source": [
    "## OSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e27ca",
   "metadata": {},
   "source": [
    "Data ingestion to the catalog can be performed in different ways, depending on **where the products are originally stored** , but also depending on **the number of products to be ingested** and therefore size.\n",
    "\n",
    "All Themes, Variables, EO Missions, Projects, Products, Workflows, and Experiments are hosted as a metadata repository placed on the GitHub platform: Git and [GitHub API](https://docs.github.com/en/rest). Each update to metadata is handled via a [Pull Request (PR)](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests). This Pull Request allows for reviewers to see the changes to be applied in advance, to check for validity of the requested changes (via an automated validation script) and to provide reviews as comments. If appropriate, the changes can be merged with the main branch of the repository. When a Pull Request is merged, the updated STAC catalog is deployed as Static Catalog.\n",
    "\n",
    "![ingest-data-scheme](https://github.com/EOEPCA/open-science-catalog-metadata/assets/120453810/5d6297e7-5d66-4564-9538-bb6eaeb92598)\n",
    "\n",
    "At the moment Open Science Catalog supports ingestion of new products either directly via **GitHub** or indirectly, using a [GUI editor](https://workspace.earthcode-staging.earthcode.eox.at/osc-editor). \n",
    "\n",
    "\n",
    "**Requirements:**\n",
    "- The Product should be related to a result of an ESA-funded project. Check if the Project's page is already existing within the ESA Open Science Catalog: [https://opensciencedata.esa.int/](https://opensciencedata.esa.int/). If not **create a Project page first.**\n",
    "- **Complete metadata available** (to correctly describe the Product)\n",
    "- The Product should be stored in an external database that is approved and a **stable data repository** (e.g. ESA PRR, CEDA Data Archive: [https://catalogue.ceda.ac.uk/](https://catalogue.ceda.ac.uk/); Zenodo repository: [https://zenodo.org/](https://zenodo.org/), etc.)\n",
    "- If the product you would like to ingest is stored elsewhere, see other data ingestion scenarios described in the section TBD.\n",
    "- Data provided in formats acceptable by GDAL and rasterio library.\n",
    "- Do you have appropriate documentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447c404",
   "metadata": {},
   "source": [
    "# Publishing workflows\n",
    "\n",
    "Workflows describe the code, enviroment and input data needed to produce results. It is strongly recommened that these be published alongside the final data products.\n",
    "\n",
    "- What code do you have?\n",
    "- What is the license?\n",
    "- What enviroment does it run in?\n",
    "- Can you show how it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d87af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fed1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
